{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) th\n#at gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-15T02:24:56.747332Z","iopub.execute_input":"2022-06-15T02:24:56.748169Z","iopub.status.idle":"2022-06-15T02:24:56.760927Z","shell.execute_reply.started":"2022-06-15T02:24:56.748133Z","shell.execute_reply":"2022-06-15T02:24:56.759673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Here starts my Baseline\n\nIdeas:\n\n1  - Feature engeneering- Basic and effective;\n\n2 - Gradient Boosting Regressions;\n\n3 - Neuronets Regressions; and\n\n4 - Submission.\n\n","metadata":{}},{"cell_type":"markdown","source":"## 1 Feature Engeneering","metadata":{}},{"cell_type":"code","source":"def concat_df(df1, df2):\n    df1 = pd.concat([df1, df2],\n                    ignore_index=True, sort=False\n                    ).drop_duplicates([\"RowId\"], keep=\"first\")\n    return df1","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:25:00.118749Z","iopub.execute_input":"2022-06-15T02:25:00.119109Z","iopub.status.idle":"2022-06-15T02:25:00.124144Z","shell.execute_reply.started":"2022-06-15T02:25:00.119079Z","shell.execute_reply":"2022-06-15T02:25:00.122944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For now... use pandas.... \n#If too heavy use Cudf\n\n# For now... just fix the floats\ndtypes = {\n'SecuritiesCode' : np.int8,\n'Open'           :     np.float16,\n'High'           :     np.float16,\n'Low'            :     np.float16,\n'Close'          :     np.float16,\n'Volume'         :       np.int8,\n'AdjustmentFactor':    np.float16,\n'ExpectedDividend':    np.float16,\n'Target'        :      np.float16\n}\npath = \"../input/jpx-tokyo-stock-exchange-prediction/\"\ndf_prices = pd.read_csv(f\"{path}train_files/stock_prices.csv\",dtype = dtypes)\nprices = pd.read_csv(f\"{path}supplemental_files/stock_prices.csv\",dtype = dtypes)\ndf_prices = concat_df(df_prices, prices)\ndf_prices = df_prices[df_prices.Date>\"2021-11-01\"]\ndf_prices.info(show_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:25:01.335729Z","iopub.execute_input":"2022-06-15T02:25:01.336717Z","iopub.status.idle":"2022-06-15T02:25:07.255895Z","shell.execute_reply.started":"2022-06-15T02:25:01.33667Z","shell.execute_reply":"2022-06-15T02:25:07.255048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def prep_prices(price):\n#     price.fillna(0,inplace=True)\n#     return price","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:25:07.257528Z","iopub.execute_input":"2022-06-15T02:25:07.258037Z","iopub.status.idle":"2022-06-15T02:25:07.262574Z","shell.execute_reply.started":"2022-06-15T02:25:07.258Z","shell.execute_reply":"2022-06-15T02:25:07.261472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_prices = prep_prices(df_prices)\n# pd.options.display.float_format = '{:,.6g}'.format\n# df_prices.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:25:07.264436Z","iopub.execute_input":"2022-06-15T02:25:07.264984Z","iopub.status.idle":"2022-06-15T02:25:07.269603Z","shell.execute_reply.started":"2022-06-15T02:25:07.264943Z","shell.execute_reply":"2022-06-15T02:25:07.268857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nimport time\n\n # auxiliary function, from datetime to timestamp\ntotimestamp = lambda s: np.int32(time.mktime(datetime.strptime(s, \"%Y-%m-%d\").timetuple()))","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:25:07.271188Z","iopub.execute_input":"2022-06-15T02:25:07.271718Z","iopub.status.idle":"2022-06-15T02:25:07.27829Z","shell.execute_reply.started":"2022-06-15T02:25:07.271679Z","shell.execute_reply":"2022-06-15T02:25:07.277482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Features\n","metadata":{}},{"cell_type":"code","source":"\n# define function to compute log returns\ndef log_return(series, periods=1):\n    return np.log(series).diff(periods=periods)\n\n\n# def fill_the_gaps(df):\n#     new_df = pd.DataFrame(columns= df.columns)\n#     for i in range(len(df['SecuritiesCode'].unique())):\n#         new_df = new_df.append(df[df['SecuritiesCode'] == i].reindex(range(df[df['SecuritiesCode'] == i].index[0],df[df['SecuritiesCode'] == i].index[-1]+60,60),method='pad'))\n#     new_df.fillna(method = 'pad', inplace = True) \n#     return new_df\n\n\ndef rsiFunc(prices, n=14):\n    deltas = np.diff(prices)\n    seed = deltas[:n+1]\n    up = seed[seed>=0].sum()/n\n    down = -seed[seed<0].sum()/n\n    rs = up/down\n    rsi = np.zeros_like(prices)\n    rsi[:n] = 100. - 100./(1.+rs)\n\n    for i in range(n, len(prices)):\n        delta = deltas[i-1] # cause the diff is 1 shorter\n\n        if delta>0:\n            upval = delta\n            downval = 0.\n        else:\n            upval = 0.\n            downval = -delta\n\n        up = (up*(n-1) + upval)/n\n        down = (down*(n-1) + downval)/n\n\n        rs = up/down\n        rsi[i] = 100. - 100./(1.+rs)\n\n    return rsi\n\n\n\ndef get_features(df):\n\n    df['log_return_5'] = log_return(df['Close'],periods=5)\n    df['log_return'] = log_return(df['Close'],periods=1)\n\n    upper_shadow = lambda asset: asset.High - np.maximum(asset.Close,asset.Open)\n    lower_shadow = lambda asset: np.minimum(asset.Close,asset.Open)- asset.Low\n\n    df['upper_shadow'] = upper_shadow(df)\n    df['lower_shadow'] = lower_shadow(df)\n    \n    df['EMA_21'] = df['Close'].ewm(span=21).mean()\n    \n    df['EMA_55'] = df['Close'].ewm(span=55).mean()\n    \n    df['EMA_315'] = df['Close'].ewm(span=315).mean()\n    \n    df['EMA_825'] = df['Close'].ewm(span=825).mean()\n    \n    window = 7\n    \n    no_of_std = 2\n    \n    df[f'EMA_{window}'] = df['Close'].ewm(span=window).mean()\n    \n    df[f'EMA_{window}_std'] = df['Close'].rolling(window=window).std()\n    \n    df[f'EMA_{window}_BB_high'] = df[f'EMA_{window}'] + no_of_std * df[f'EMA_{window}_std']\n    \n    df[f'MA_{window}MA_BB_low'] = df[f'EMA_{window}'] - no_of_std * df[f'EMA_{window}_std']\n    \n    window = 5\n    \n    df[f'EMA_{window}'] = df['Close'].ewm(span=window).mean()\n    \n    df[f'EMA_{window}_std'] = df['Close'].rolling(window=window).std()\n    \n    df[f'EMA_{window}_BB_high'] = df[f'EMA_{window}'] + no_of_std * df[f'EMA_{window}_std']\n    \n    df[f'MA_{window}MA_BB_low'] = df[f'EMA_{window}'] - no_of_std * df[f'EMA_{window}_std']\n    \n    df['MACD'] = df['EMA_7'] - df['EMA_5']\n    \n    \n    df['rsi_5'] = rsiFunc(df['Close'].values, 5)\n    \n    df['rsi_7'] = rsiFunc(df['Close'].values, 7)\n    \n    df['rsi_21'] = rsiFunc(df['Close'].values, 21)\n    \n    \n    \n    #df['VWAP'] = (df['Close'] * df['Volume'])/ df['Volume']\n\n    #df['dayofweek'] = df['dt'].dt.dayofweek\n\n\n    \n    \n    #df = pd.concat([df, pd.get_dummies(df['Asset_ID'], prefix= 'Asset_')], axis=1)\n    \n    df[['log_return_5', 'log_return', 'upper_shadow', 'lower_shadow',\n       'EMA_21', 'EMA_55', 'EMA_315', 'EMA_825', 'EMA_7', 'EMA_7_std',\n       'EMA_7_BB_high', 'MA_7MA_BB_low', 'EMA_5', 'EMA_5_std', 'EMA_5_BB_high',\n       'MA_5MA_BB_low', 'MACD', 'rsi_5', 'rsi_7', 'rsi_21']].astype('float16')\n    \n    return df\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:25:08.593739Z","iopub.execute_input":"2022-06-15T02:25:08.594352Z","iopub.status.idle":"2022-06-15T02:25:08.61489Z","shell.execute_reply.started":"2022-06-15T02:25:08.594321Z","shell.execute_reply":"2022-06-15T02:25:08.613949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_prices = get_features(df_prices)\n\ndf_prices = df_prices.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n\ndf_prices = df_prices.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:25:09.172591Z","iopub.execute_input":"2022-06-15T02:25:09.173221Z","iopub.status.idle":"2022-06-15T02:25:14.611815Z","shell.execute_reply.started":"2022-06-15T02:25:09.173184Z","shell.execute_reply":"2022-06-15T02:25:14.610959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training a Simple Model\n\nXgboost","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:25:20.145871Z","iopub.execute_input":"2022-06-15T02:25:20.146222Z","iopub.status.idle":"2022-06-15T02:25:20.150351Z","shell.execute_reply.started":"2022-06-15T02:25:20.146193Z","shell.execute_reply":"2022-06-15T02:25:20.149571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_training(X,y):\n    # Model training\n    \n    model = xgb.XGBRegressor(n_estimators=5000,learning_rate=0.1 , tree_method = 'gpu_hist') \n    model.fit(X, y)\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:34:45.211855Z","iopub.execute_input":"2022-06-15T02:34:45.212208Z","iopub.status.idle":"2022-06-15T02:34:45.216957Z","shell.execute_reply.started":"2022-06-15T02:34:45.21218Z","shell.execute_reply":"2022-06-15T02:34:45.216209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_features = ['Open', 'High', 'Low', 'Close', 'Volume','log_return_5', 'log_return', 'upper_shadow', 'lower_shadow',\n       'EMA_21', 'EMA_55', 'EMA_315', 'EMA_825', 'EMA_7', 'EMA_7_std',\n       'EMA_7_BB_high', 'MA_7MA_BB_low', 'EMA_5', 'EMA_5_std', 'EMA_5_BB_high',\n       'MA_5MA_BB_low', 'MACD', 'rsi_5', 'rsi_7', 'rsi_21']\nfeatures = ['Open', 'High', 'Low', 'Close', 'Volume', 'log_return_5', 'log_return', 'upper_shadow', 'lower_shadow',\n       'EMA_21', 'EMA_55', 'EMA_315', 'EMA_825', 'EMA_7', 'EMA_7_std',\n       'EMA_7_BB_high', 'MA_7MA_BB_low', 'EMA_5', 'EMA_5_std', 'EMA_5_BB_high',\n       'MA_5MA_BB_low', 'MACD', 'rsi_5', 'rsi_7', 'rsi_21']","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:58:52.798363Z","iopub.execute_input":"2022-06-15T02:58:52.799136Z","iopub.status.idle":"2022-06-15T02:58:52.829385Z","shell.execute_reply.started":"2022-06-15T02:58:52.799042Z","shell.execute_reply":"2022-06-15T02:58:52.828673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating endog and exog variables\ny = df_prices[['Target']]\nX = df_prices[features]","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:34:47.931987Z","iopub.execute_input":"2022-06-15T02:34:47.932341Z","iopub.status.idle":"2022-06-15T02:34:47.96236Z","shell.execute_reply.started":"2022-06-15T02:34:47.93231Z","shell.execute_reply":"2022-06-15T02:34:47.961317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[scaled_features] = scaler.fit_transform(X[scaled_features])\n","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:34:48.912072Z","iopub.execute_input":"2022-06-15T02:34:48.912444Z","iopub.status.idle":"2022-06-15T02:34:51.932336Z","shell.execute_reply.started":"2022-06-15T02:34:48.912399Z","shell.execute_reply":"2022-06-15T02:34:51.931369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nmodel_1 = model_training(X,y)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:34:51.94905Z","iopub.execute_input":"2022-06-15T02:34:51.949586Z","iopub.status.idle":"2022-06-15T02:35:40.082161Z","shell.execute_reply.started":"2022-06-15T02:34:51.949558Z","shell.execute_reply":"2022-06-15T02:35:40.081353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.score(X,y)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:35:40.083702Z","iopub.execute_input":"2022-06-15T02:35:40.084038Z","iopub.status.idle":"2022-06-15T02:36:30.987718Z","shell.execute_reply.started":"2022-06-15T02:35:40.084003Z","shell.execute_reply":"2022-06-15T02:36:30.986986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:36:30.989122Z","iopub.execute_input":"2022-06-15T02:36:30.989884Z","iopub.status.idle":"2022-06-15T02:36:30.994408Z","shell.execute_reply.started":"2022-06-15T02:36:30.989847Z","shell.execute_reply":"2022-06-15T02:36:30.993797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving model\n\n#Saving the sklearn model\n\nfilename = 'simple_xgb.sav'\npickle.dump(model_1, open(filename, 'wb'))\n\n# save in text format\nmodel_1.save_model(\"simple_xgb.txt\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:36:30.996372Z","iopub.execute_input":"2022-06-15T02:36:30.996917Z","iopub.status.idle":"2022-06-15T02:36:31.456112Z","shell.execute_reply.started":"2022-06-15T02:36:30.996888Z","shell.execute_reply":"2022-06-15T02:36:31.455132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission\n","metadata":{}},{"cell_type":"code","source":"# def calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n#     \"\"\"\n#     Args:\n#         df (pd.DataFrame): predicted results\n#         portfolio_size (int): # of equities to buy/sell\n#         toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n#     Returns:\n#         (float): spread return\n#     \"\"\"\n#     assert df['Rank'].min() == 0\n#     assert df['Rank'].max() == len(df['Rank']) - 1\n#     weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n#     purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n#     short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n#     return purchase - short\n\n# def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n#     \"\"\"\n#     Args:\n#         df (pd.DataFrame): predicted results\n#         portfolio_size (int): # of equities to buy/sell\n#         toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n#     Returns:\n#         (float): sharpe ratio\n#     \"\"\"\n#     buf = df.groupby('Date').apply(calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n#     sharpe_ratio = buf.mean() / buf.std()\n#     return sharpe_ratio, buf\n\ndef add_rank(df, col_name=\"pred\"):\n    df[\"Rank\"] = df.groupby(\"Date\")[col_name].rank(ascending=False, method=\"first\") - 1 \n    df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:13:30.132942Z","iopub.execute_input":"2022-06-15T02:13:30.133309Z","iopub.status.idle":"2022-06-15T02:13:30.140366Z","shell.execute_reply.started":"2022-06-15T02:13:30.133276Z","shell.execute_reply":"2022-06-15T02:13:30.13923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # By Yuike - https://www.kaggle.com/code/ikeppyo/examples-of-higher-scores-than-perfect-predictions\n\n# # This function adjusts the predictions so that the daily spread return approaches a certain value.\n# def adjuster(df):\n#     def calc_pred(df, x, y, z):\n#         return df['Target'].where(df['Target'].abs() < x, df['Target'] * y + np.sign(df['Target']) * z)\n\n#     def objective(trial, df):\n#         x = trial.suggest_uniform('x', 0, 0.2)\n#         y = trial.suggest_uniform('y', 0, 0.1)\n#         z = trial.suggest_uniform('z', 0, 1e-3)\n#         df[\"Rank\"] = calc_pred(df, x, y, z).rank(ascending=False, method=\"first\") - 1 \n#         df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n#         return calc_spread_return_per_day(df, 200, 2)\n    \n#     def predictor_per_day(df):\n#         study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=2022))\n#         study.optimize(lambda trial: abs(objective(trial, df) - 10), 10)\n#         return calc_pred(df, *study.best_params.values())\n\n#     return df.groupby(\"Date\").apply(predictor_per_day).reset_index(level=0, drop=True)\n\n# def _predictor_base(feature_df):\n#     return model.predict(feature_df[feats])\n\n# def _predictor_with_adjuster(feature_df):\n#     feature_df[\"Target\"] = model.predict(feature_df[feats])\n#     return adjuster(feature_df)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T00:36:20.556101Z","iopub.execute_input":"2022-06-15T00:36:20.556492Z","iopub.status.idle":"2022-06-15T00:36:20.568645Z","shell.execute_reply.started":"2022-06-15T00:36:20.556449Z","shell.execute_reply":"2022-06-15T00:36:20.567757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictor = _predictor_with_adjuster","metadata":{"execution":{"iopub.status.busy":"2022-06-15T00:38:51.635129Z","iopub.execute_input":"2022-06-15T00:38:51.635586Z","iopub.status.idle":"2022-06-15T00:38:51.639976Z","shell.execute_reply.started":"2022-06-15T00:38:51.635532Z","shell.execute_reply":"2022-06-15T00:38:51.638842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jpx_tokyo_market_prediction\n\n\nenv = jpx_tokyo_market_prediction.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test files\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    prices = get_features(prices)\n    prices = prices.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n    prices = prices.fillna(0)\n    prices[scaled_features] = scaler.fit_transform(prices[scaled_features])\n    prices['pred'] = model_1.predict(prices[features])\n    prices = add_rank(prices)\n    feature_map = prices.set_index('SecuritiesCode')['Rank'].to_dict()\n    sample_prediction['Rank'] = sample_prediction['SecuritiesCode'].map(feature_map)\n    env.predict(sample_prediction)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T02:37:27.615593Z","iopub.execute_input":"2022-06-15T02:37:27.616451Z","iopub.status.idle":"2022-06-15T02:37:27.648982Z","shell.execute_reply.started":"2022-06-15T02:37:27.616394Z","shell.execute_reply":"2022-06-15T02:37:27.648098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}